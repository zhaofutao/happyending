# 一、基本原理
        Lucene是一个高效的、基于Java的全文检索库。
        我们生活中的数据总体分为两种：结构化数据和非结构化数据；
      结构化数据：是指具有固定格式或有限长度的数据，如数据库、元数据等；对结构化数据的搜索，如对数据库的搜索，用SQL语句；再如对元数据的搜索，如利用windows搜索对文件名、类型、修改时间进行搜索等。
      非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等。对非结构化数据的搜索，如利用windows的搜索可以搜索文件内容，Linux下的grep命令，再如用Google和百度可以搜索大量内容数据。
      对非结构化数据也即全文搜索主要有两种方法：
      一种是顺序扫描法，比如要找内容包含某一个字符串的文件，就是一个文档一个文档的看，直到扫描完所有的文件。
      另一种方法也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。这种先建索引，然后对索引进行搜索的过程就叫做全文检索（Full-text Search）。

      全文检索大体分为两个过程，索引创建（Indexing）和搜索索引（Search）。
      索引创建：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。
      搜索索引：得到用户的查询请求，搜索创建的索引，然后返回结果的过程。

# 二、基本概念  
- 反向索引  
非结构化数据中所存储的信息是每个文件包含哪些字符串，也即已知文件，欲求字符串相对容易，也即是从文件到字符串的映射。
而我们搜索的信息是哪些文件包含此字符串，也即已知字符串，欲求文件，也即从字符串到文件的映射。
由于从字符串到文件的映射是文件到字符串映射的反向过程，于是保存这种信息的索引称为反向索引。

- 倒排表（Posting List）
每个字符串到包含此字符串的文档（Document）是以链表的形式存储，此文档链表称为倒排链表。

# 三、如何创建索引
1. 将文档传递给分词组件(Tokenizer)  
   1. 将文档分词一个一个单独的单词；  
   2. 去除标点符号；
   3. 去除停词（stop word）（太普通，不能代表任何意义，去掉停词有助与减少长尾现象）  
   4. 经过分词处理的结果成为词元（token）
2. 将得到的词元传递给语言处理组件（Linguistic Processor）
   语言处理组件(linguistic processor)主要是对得到的词元做一些同语言相关的处理。对于英语而言，一般做到如下几点：
   1. 统一大小写（lowercase）
   2. 将单词缩减为词根形式，如"cars"变为"car"，这种操作称为stemming.
   3. 将单词转变为词根形式，如"drove"到"drive"，这种操作称为lemmatization.
   4. 语言处理组件处理的结果成为词（Term）
3. 将得到的词（Term）传给索引组件（Indexer）
    索引组件主要作以下几件事：
    1. 利用得到的词（Term）创建一个字典；
    2. 对字典按字母顺序进行排序；
    3. 合并相同的词成为文档倒排(Posting List)链表；在此表中，有几个定义：
       1. Document Frequency：文档频次，表示总共有多少个文件包含此词。
       2. Frequency：词频率，此文件包含了几个这个词；

# 四、如何对索引进行搜索
1. 用户输入查询语句
2. 对查询语句进行词法分析、语法分析及语言处理；
   1. 词法分析主要用来识别单次和关键词；
   2. 语法分析主要是根据语句的语法规则来形成一颗语法树；
   3. 语言处理同索引过程中的语言处理几乎相同；
3. 搜索索引，得到符合语法树的文档。
    此步骤有分几小部：
    1. 在文档倒排链表中，找到包含搜索词的文档链表；
    2. 对多个文档链表合并处理，得到我们想要找的文档。
4. 根据得到的文档和查询语句的相关性，对结果进行排序。
   1. 计算权重（Term Weight）的过程
   影响一个词在一篇文档中的重要性主要有2个因素：
      1. Term Frequency(tf)：即此词在此文档中出现了多少次，tf越大说明越重要；
      2. Document Frequency(df)：即有多少文档包含此Term，df越大说明越不重要；  
      3. 权重计算公式：$W_1$ = $tf_t,d$ × log(n / $df_t$)
   2. 判断Term之间的关系从而得到文档相关性的过程，也即向量空间模型的算法（VSM）
    我们把文档看做一些列词，每个词都有一个权重，不同的词根据自己在文档中的权重来影响文档相关性的打分计算。  
    于是我们把所有此文档中词的权重看成一个向量：  
    Document Vector = {term1 : weight1, term2 : weight2, ... , termN : weightN}  
    我们把所有搜索出来的文档向量及查询向量放在一个N维空间中，每个词是一维，然后我们通过计算两个向量的余弦计算相关性打分。
    
    
